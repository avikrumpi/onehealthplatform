# FastAPI Backend Server for Narishakti Chatbot
# Fixed RAG retrieval issue - properly extracts Bengali answers and queries corpus
# Added doctor contact retrieval functionality

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import os
import asyncio
import re
import requests
from bs4 import BeautifulSoup

# Import RAG system setup
try:
    from botretrieval import setup_rag_system, MODEL_NAME, API_KEY, CORPUS_FILES
    from langchain.prompts import PromptTemplate
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    from langchain.chains import ConversationalRetrievalChain
    from langchain.memory import ConversationBufferMemory
    from langchain_community.vectorstores import Chroma
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.document_loaders import TextLoader

    print("‚úÖ Successfully imported required modules")
except ImportError as e:
    print(f"‚ùå Error importing modules: {e}")
    exit(1)


# QueryData requires all of these fields
class QueryData(BaseModel):
    prompt: str
    q1ToQ5History: Optional[List[str]] = []  # Added Optional and default
    q6ToQ12History: Optional[List[str]] = []  # Added Optional and default
    conversationHistory: Optional[List[str]] = []  # Added Optional and default
    district_selection: Optional[str] = None

# Women's Health Resources Data - matching chatbotapp.py exactly
WOMENS_HEALTH_RESOURCES = {
    "‡¶¨‡ßÄ‡¶∞‡¶≠‡ßÇ‡¶Æ": {
        "centers": [
            {"name": "‡¶¨‡ßÄ‡¶∞‡¶≠‡ßÇ‡¶Æ ‡¶ú‡ßá‡¶≤‡¶æ ‡¶π‡¶æ‡¶∏‡¶™‡¶æ‡¶§‡¶æ‡¶≤ ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó", "phone": "03462-255200", "address": "‡¶∏‡¶ø‡¶â‡¶°‡¶º‡¶ø, ‡¶¨‡ßÄ‡¶∞‡¶≠‡ßÇ‡¶Æ"},
            {"name": "‡¶Æ‡¶æ‡¶§‡ßÉ‡¶§‡ßç‡¶¨ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞, ‡¶∞‡¶æ‡¶Æ‡¶™‡ßÅ‡¶∞‡¶π‡¶æ‡¶ü", "phone": "03461-222001", "address": "‡¶∞‡¶æ‡¶Æ‡¶™‡ßÅ‡¶∞‡¶π‡¶æ‡¶ü"},
            {"name": "Tele-MANAS (‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡ß®‡ß™/‡ß≠ ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ)", "phone": "14416", "address": "‡ß®‡ß™/‡ß≠ ‡¶∏‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ"}
        ],
        "doctors": [
            {"name": "‡¶°. ‡¶Æ‡¶æ‡¶≤‡¶¨‡¶ø‡¶ï‡¶æ ‡¶Æ‡ßÅ‡¶ñ‡¶æ‡¶∞‡ßç‡¶ú‡ßÄ (‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830012345"},
            {"name": "‡¶°. ‡¶∂‡¶∞‡ßç‡¶Æ‡¶ø‡¶∑‡ßç‡¶†‡¶æ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶®‡¶æ‡¶∞‡ßç‡¶ú‡ßÄ (‡¶™‡ßç‡¶∞‡¶∏‡ßÇ‡¶§‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830023456"}
        ]
    },
    "‡¶™‡ßÅ‡¶∞‡ßÅ‡¶≤‡¶ø‡¶Ø‡¶º‡¶æ": {
        "centers": [
            {"name": "‡¶™‡ßÅ‡¶∞‡ßÅ‡¶≤‡¶ø‡¶Ø‡¶º‡¶æ ‡¶∏‡¶¶‡¶∞ ‡¶π‡¶æ‡¶∏‡¶™‡¶æ‡¶§‡¶æ‡¶≤ ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó", "phone": "03252-222001", "address": "‡¶™‡ßÅ‡¶∞‡ßÅ‡¶≤‡¶ø‡¶Ø‡¶º‡¶æ ‡¶∂‡¶π‡¶∞"},
            {"name": "‡¶™‡ßç‡¶∞‡¶æ‡¶•‡¶Æ‡¶ø‡¶ï ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞, ‡¶ù‡¶æ‡¶≤‡¶¶‡¶æ", "phone": "03253-245001", "address": "‡¶ù‡¶æ‡¶≤‡¶¶‡¶æ"}
        ],
        "doctors": [
            {"name": "‡¶°. ‡¶Ö‡¶®‡¶ø‡¶®‡ßç‡¶¶‡¶ø‡¶§‡¶æ ‡¶¶‡¶æ‡¶∏ (‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830034567"},
            {"name": "‡¶°. ‡¶∞‡ßÄ‡¶§‡¶æ ‡¶∏‡ßá‡¶® (‡¶™‡ßç‡¶∞‡¶∏‡ßÇ‡¶§‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830045678"}
        ]
    },
    "‡¶¨‡¶æ‡¶Å‡¶ï‡ßÅ‡¶°‡¶º‡¶æ": {
        "centers": [
            {"name": "‡¶¨‡¶æ‡¶Å‡¶ï‡ßÅ‡¶°‡¶º‡¶æ ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶ø‡¶≤‡¶®‡ßÄ ‡¶Æ‡ßá‡¶°‡¶ø‡¶ï‡ßá‡¶≤ ‡¶ï‡¶≤‡ßá‡¶ú ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó", "phone": "7029473375",
             "address": "‡¶¨‡¶æ‡¶Å‡¶ï‡ßÅ‡¶°‡¶º‡¶æ ‡¶∏‡¶¶‡¶∞"},
            {"name": "‡¶Æ‡¶æ‡¶§‡ßÉ‡¶§‡ßç‡¶¨ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞, ‡¶ñ‡¶æ‡¶§‡¶∞‡¶æ", "phone": "03242-267001", "address": "‡¶ñ‡¶æ‡¶§‡¶∞‡¶æ"}
        ],
        "doctors": [
            {"name": "‡¶°. ‡¶¶‡ßá‡¶¨‡¶Ø‡¶æ‡¶®‡ßÄ ‡¶∞‡¶æ‡¶Ø‡¶º (‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830056789"},
            {"name": "‡¶°. ‡¶∂‡ßç‡¶∞‡ßá‡¶Ø‡¶º‡¶∏‡ßÄ ‡¶ò‡ßã‡¶∑ (‡¶™‡ßç‡¶∞‡¶∏‡ßÇ‡¶§‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830067890"}
        ]
    },
    "‡¶¨‡¶∞‡ßç‡¶ß‡¶Æ‡¶æ‡¶®": {
        "centers": [
            {"name": "‡¶¨‡¶∞‡ßç‡¶ß‡¶Æ‡¶æ‡¶® ‡¶Æ‡ßá‡¶°‡¶ø‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶ï‡¶≤‡ßá‡¶ú ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó", "phone": "0342-2662000", "address": "‡¶¨‡¶∞‡ßç‡¶ß‡¶Æ‡¶æ‡¶® ‡¶∂‡¶π‡¶∞"},
            {"name": "‡¶Æ‡¶æ‡¶§‡ßÉ‡¶§‡ßç‡¶¨ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞, ‡¶ï‡¶æ‡¶ü‡ßã‡¶Ø‡¶º‡¶æ", "phone": "03453-252001", "address": "‡¶ï‡¶æ‡¶ü‡ßã‡¶Ø‡¶º‡¶æ"}
        ],
        "doctors": [
            {"name": "‡¶°. ‡¶∏‡ßÅ‡¶Æ‡¶ø‡¶§‡¶æ ‡¶ö‡¶ü‡ßç‡¶ü‡ßã‡¶™‡¶æ‡¶ß‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º (‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830078901"},
            {"name": "‡¶°. ‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶ø‡¶Æ‡¶æ ‡¶∏‡¶æ‡¶π‡¶æ (‡¶™‡ßç‡¶∞‡¶∏‡ßÇ‡¶§‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830089012"}
        ]
    },
    "‡¶Ü‡¶∏‡¶æ‡¶®‡¶∏‡ßã‡¶≤": {
        "centers": [
            {"name": "‡¶Ü‡¶∏‡¶æ‡¶®‡¶∏‡ßã‡¶≤ ‡¶ú‡ßá‡¶≤‡¶æ ‡¶π‡¶æ‡¶∏‡¶™‡¶æ‡¶§‡¶æ‡¶≤ ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó", "phone": "0341-2203101", "address": "‡¶Ü‡¶∏‡¶æ‡¶®‡¶∏‡ßã‡¶≤"},
            {"name": "‡¶Æ‡¶æ‡¶§‡ßÉ‡¶§‡ßç‡¶¨ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞, ‡¶¨‡¶æ‡¶∞‡ßç‡¶®‡¶™‡ßÅ‡¶∞", "phone": "0341-2274001", "address": "‡¶¨‡¶æ‡¶∞‡ßç‡¶®‡¶™‡ßÅ‡¶∞"}
        ],
        "doctors": [
            {"name": "‡¶°. ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶®‡¶æ‡¶∞‡ßç‡¶ú‡ßÄ (‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830090123"},
            {"name": "‡¶°. ‡¶Æ‡ßå‡¶∏‡ßÅ‡¶Æ‡ßÄ ‡¶¶‡¶æ‡¶∏ (‡¶™‡ßç‡¶∞‡¶∏‡ßÇ‡¶§‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û)", "phone": "9830091234"}
        ]
    }
}

DISTRICTS = list(WOMENS_HEALTH_RESOURCES.keys())

# Initialize FastAPI app
app = FastAPI(title="Narishakti Health Chatbot API")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global RAG chain variable
rag_chain = None


def extract_bengali_answers(qa_history: str) -> str:
    """
    Extracts only the Bengali answers from Q&A history
    Removes Q1, A1, Q2, A2 format and English metadata
    """
    answers = []
    lines = qa_history.split('\n')

    for line in lines:
        # Match pattern like "A1: ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ text" or "A‡ß®: ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ text"
        if line.strip().startswith('A') or 'A' in line[:5]:
            # Extract everything after the colon
            parts = line.split(':', 1)
            if len(parts) > 1:
                answer = parts[1].strip()
                if answer:  # Only add non-empty answers
                    answers.append(answer)

    return ' | '.join(answers)


def create_bengali_query(category: str, subcategory: str, answers: str, stage: str) -> str:
    """
    Creates a focused Bengali query that matches corpus content
    """
    # Map English category names to Bengali
    category_map = {
        'menstrual_health': '‡¶Æ‡¶æ‡¶∏‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ',
        'reproductive_sexual_health': '‡¶™‡ßç‡¶∞‡¶ú‡¶®‡¶® ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø',
        'PCOS_hormonal_health': 'PCOS ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ',
        'cancer_health': '‡¶ï‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏‡¶æ‡¶∞',
        'other_health': '‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ'
    }

    bengali_category = category_map.get(category, category)

    if stage == "after_q5":
        query = f"{bengali_category} ‡¶è‡¶¨‡¶Ç {subcategory} ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡¶ø‡¶®‡•§ ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø: {answers}"
    elif stage == "after_q12":
        query = f"{bengali_category} ‡¶è‡¶¨‡¶Ç {subcategory} ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂, ‡¶ñ‡¶æ‡¶¶‡ßç‡¶Ø‡¶æ‡¶≠‡ßç‡¶Ø‡¶æ‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶¨‡¶≤‡ßÅ‡¶®‡•§ ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶§‡¶•‡ßç‡¶Ø: {answers}"
    else:
        query = f"{bengali_category}: {answers}"

    return query


def get_doctor_contacts_for_district(district: str) -> str:
    """
    Returns formatted doctor contact information for a specific district
    """
    if district not in WOMENS_HEALTH_RESOURCES:
        return f"‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, '{district}' ‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø‡•§\n\n**‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶ú‡ßá‡¶≤‡¶æ:** {', '.join(DISTRICTS)}"

    data = WOMENS_HEALTH_RESOURCES[district]

    result = f"### üè• {district} ‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡ßá‡¶¨‡¶æ\n\n"
    result += "#### üè® **‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞:**\n\n"

    for center in data["centers"]:
        result += f"**{center['name']}**\n"
        result += f"üìû ‡¶´‡ßã‡¶®: {center['phone']}\n"
        result += f"üìç ‡¶†‡¶ø‡¶ï‡¶æ‡¶®‡¶æ: {center['address']}\n\n"

    result += "#### üë©‚Äç‚öïÔ∏è **‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û:**\n\n"

    for doctor in data["doctors"]:
        result += f"**{doctor['name']}**\n"
        result += f"üìû ‡¶´‡ßã‡¶®: {doctor['phone']}\n\n"

    return result


# Initialize RAG system with custom configuration
@app.on_event("startup")
async def startup_event():
    """Initialize RAG system with enhanced retrieval"""
    global rag_chain
    print("\n" + "=" * 60)
    print("üöÄ Starting Narishakti Health Chatbot Backend Server...")
    print("=" * 60)

    print("\nüîÑ Initializing Enhanced RAG system...")
    print(f"üìÇ Corpus files: {CORPUS_FILES}")
    print(f"ü§ñ Model: {MODEL_NAME}")

    # Check corpus files
    missing_files = []
    total_chars = 0
    for file in CORPUS_FILES:
        if not os.path.exists(file):
            missing_files.append(file)
        else:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
                chars = len(content)
                total_chars += chars
                print(f"   ‚úì {file}: {chars:,} characters")

    if missing_files:
        print(f"\n‚ùå ERROR: Missing corpus files: {missing_files}")
        exit(1)

    print(f"\nüìä Total corpus size: {total_chars:,} characters")

    try:
        # Load all corpus documents manually for better control
        print("\nüìö Loading corpus documents...")
        all_documents = []
        for corpus_file in CORPUS_FILES:
            try:
                loader = TextLoader(corpus_file, encoding='utf-8')
                documents = loader.load()
                all_documents.extend(documents)
                print(f"   ‚úì Loaded {len(documents)} documents from {corpus_file}")
            except Exception as e:
                print(f"   ‚úó Error loading {corpus_file}: {e}")

        if not all_documents:
            raise ValueError("No documents loaded from corpus files")

        print(f"\nüìÑ Total documents loaded: {len(all_documents)}")

        # Split with Bengali-optimized settings
        print("\n‚úÇÔ∏è Splitting documents into chunks...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # Smaller chunks for better matching
            chunk_overlap=150,  # More overlap for context
            separators=["\n\n", "\n", "‡•§", ".", " ", ""]
        )
        texts = text_splitter.split_documents(all_documents)
        print(f"   ‚úì Created {len(texts)} text chunks")

        # Create embeddings and vector store
        print("\nüîó Creating embeddings and vector store...")
        embeddings = OpenAIEmbeddings(api_key=API_KEY)
        vectorstore = Chroma.from_documents(texts, embeddings)

        # Enhanced retriever with more chunks
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 6}  # Retrieve top 6 chunks instead of 3
        )
        print("   ‚úì Vector store created with enhanced retrieval (k=6)")

        # LLM with better configuration for Bengali
        llm = ChatOpenAI(
            model=MODEL_NAME,
            api_key=API_KEY,
            temperature=0.4,  # Slightly more creative
            max_tokens=1300  # Allow longer responses
        )
        print(f"   ‚úì LLM initialized: {MODEL_NAME} (temp=0.4, max_tokens=1300)")

        # Conversation memory
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key='answer',
            input_key='question'
        )
        print("   ‚úì Conversation memory initialized")

        # Create custom prompt for Bengali health advice
        qa_prompt_template = """‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂‡¶¶‡¶æ‡¶§‡¶æ‡•§ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó (Context) ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡¶æ‡¶ì‡•§

**‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£: ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶§‡¶•‡ßç‡¶Ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã‡•§ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã ‡¶®‡¶æ‡•§**

‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó (Corpus Documents):
{context}

‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {question}

‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ:

-‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì (‡¶™‡¶∂‡ßç‡¶ö‡¶ø‡¶Æ‡¶¨‡¶ô‡ßç‡¶ó‡ßá‡¶∞ ‡¶ö‡¶≤‡¶ø‡¶§ ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã)

-‡ß©‡ß¶‡ß¶-‡ß´‡ß¶‡ß¶ ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶ì ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡¶æ‡¶ì

-‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ‡¶§‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡ßã‚Äî‚Äò‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶Æ‡ßÅ‡¶ñ‡ßÄ‡¶® ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡¶®, ‡¶§‡¶æ ‡¶π‡¶≤‡ßã:‚Ä¶‚Äô, ‡¶è‡¶¨‡¶Ç ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ‡¶§‡ßá ‡¶∏‡ßá‡¶á ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì

-‡¶è‡¶ï‡¶á ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ ‡¶¨‡¶æ ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶¨‡¶æ‡¶∞‡¶Ç‡¶¨‡¶æ‡¶∞ ‡¶™‡ßÅ‡¶®‡¶∞‡¶æ‡¶¨‡ßÉ‡¶§‡ßç‡¶§‡¶ø ‡¶è‡¶°‡¶º‡¶ø‡¶Ø‡¶º‡ßá ‡¶ö‡¶≤‡ßã; ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§, ‡¶Ö‡¶∞‡ßç‡¶•‡¶¨‡¶π ‡¶è‡¶¨‡¶Ç ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶Æ‡¶§‡¶æ‡¶Æ‡¶§ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßã

-‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó (Context) ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø, ‡¶¨‡¶ü ‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶´‡¶≤‡ßã-‡¶Ü‡¶™ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡¶¨‡ßá, ‡¶¨‡¶ü ‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡¶ï‡ßá ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶Ö‡¶™‡¶∂‡¶®, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ì ‡¶¨‡¶æ‡¶ü‡¶® ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ø‡ßá‡¶∏‡¶¨ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá, ‡¶∏‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™‡ßá ‡¶∏‡¶æ‡¶∞‡¶æ‡¶Ç‡¶∂ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá ‡•§ ‡¶è‡¶∞‡¶™‡¶∞, ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶™‡¶ï, ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶ì ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá

-‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá‚Äî‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂, ‡¶ñ‡¶æ‡¶¶‡ßç‡¶Ø‡¶æ‡¶≠‡ßç‡¶Ø‡¶æ‡¶∏, ‡¶ú‡ßÄ‡¶¨‡¶®‡¶Ø‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡¶æ‡¶ì; ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶ï‡ßã‡¶®‡ßã ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑ ‡¶∂‡¶∞‡ßç‡¶§ (‡¶Ø‡ßá‡¶Æ‡¶®: ‡¶°‡¶æ‡¶Ø‡¶º‡¶æ‡¶¨‡ßá‡¶ü‡¶ø‡¶∏, ‡¶ó‡¶∞‡ßç‡¶≠‡¶æ‡¶¨‡¶∏‡ßç‡¶•‡¶æ, ‡¶ñ‡¶æ‡¶¶‡ßç‡¶Ø-‡¶è‡¶≤‡¶æ‡¶∞‡ßç‡¶ú‡¶ø, ‡¶π‡ßÉ‡¶¶‡¶∞‡ßã‡¶ó) ‡¶¶‡¶ø‡¶≤‡ßá, ‡¶è ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ‡¶≠‡¶æ‡¶¨‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ì ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¶‡¶æ‡¶ì

-‡¶∏‡¶π‡¶ú‡¶¨‡ßã‡¶ß‡ßç‡¶Ø ‡¶ì ‡¶á‡¶§‡¶ø‡¶¨‡¶æ‡¶ö‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã, ‡¶Ø‡¶æ‡¶§‡ßá ‡¶∏‡¶ï‡¶≤‡ßá‡¶á ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®

-‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶§ ‡¶§‡¶•‡ßç‡¶Ø ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá ‡¶¨‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶Ü‡¶∏‡ßá‡¶®‡¶æ, ‡¶§‡¶ñ‡¶® ‡¶≤‡¶ø‡¶ñ‡ßã‚Äî
‚Äú‡¶è ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∞‡¶ì ‡¶∏‡¶†‡¶ø‡¶ï ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü‡¶ü‡¶ø ‡¶Æ‡¶®‡ßã‡¶Ø‡ßã‡¶ó ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶ñ‡ßã ‡¶Ö‡¶•‡¶¨‡¶æ ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶∏‡¶Ç‡¶∂‡ßç‡¶≤‡¶ø‡¶∑‡ßç‡¶ü ‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶ï‡ßá‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßã‡•§‚Äù

‡¶è‡¶≠‡¶æ‡¶¨‡ßá, ‡¶á‡¶â‡¶ú‡¶æ‡¶∞-‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ï‡¶∂‡¶® (‡¶Ö‡¶™‡¶∂‡¶®-‡¶¨‡¶æ‡¶ü‡¶®/‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®) ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡ßá Context-‡¶è ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™‡ßá ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶ø‡¶§ ‡¶π‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶Æ‡ßÇ‡¶≤ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø-‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡ßá‡¶á ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø ‡¶ï‡¶∞‡ßá ‡¶™‡ßÅ‡¶∞‡ßã‡¶™‡ßÅ‡¶∞‡¶ø West Bengal-‡¶è‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡¶¨‡ßá‡•§‚Äù

‡¶â‡¶§‡ßç‡¶§‡¶∞ (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º):"""

        from langchain.prompts import PromptTemplate
        QA_PROMPT = PromptTemplate(
            template=qa_prompt_template,
            input_variables=["context", "question"]
        )

        # Create RAG chain with custom prompt
        rag_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            memory=memory,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": QA_PROMPT},
            verbose=True  # Enable verbose for debugging
        )

        print("\n‚úÖ Enhanced RAG Chain initialized successfully!")
        print("   - Optimized for Bengali health queries")
        print("   - Custom prompt for detailed advice")
        print("   - Enhanced retrieval (6 chunks)")
        print("   - Verbose logging enabled")

    except Exception as e:
        print(f"\n‚ùå Error initializing RAG system: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

    print("\n" + "=" * 60)
    print("üå∏ ‡¶®‡¶æ‡¶∞‡ßÄ‡¶∂‡¶ï‡ßç‡¶§‡¶ø RAG System Ready!")
    print("=" * 60 + "\n")


# Request/Response models
class RAGQueryRequest(BaseModel):
    query: str
    conversation_history: List[str]
    question_stage: Optional[str]


class RAGQueryResponse(BaseModel):
    answer: str
    citations: Optional[str] = None  # Not a list, just a string
    status: str

class DoctorContactRequest(BaseModel):
    district: str


class DoctorContactResponse(BaseModel):
    district: str
    contact_info: str
    status: str = "success"

# ============================================================================
# FAVICON ROUTE (Optional - prevents 404 in logs)
# ============================================================================

@app.get("/favicon.ico")
async def favicon():
    """Handle favicon requests"""
    from fastapi.responses import Response
    return Response(status_code=204)  # 204 = No Content

@app.get("/")
async def serve_frontend():
    """Serve HTML frontend"""
    html_path = "index_womenhealth.html"
    if os.path.exists(html_path):
        return FileResponse(
            html_path,
            headers={
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )
    else:
        return {
            "status": "running",
            "message": "Narishakti Health Chatbot API",
            "rag_status": "initialized" if rag_chain else "not_initialized"
        }

@app.get("/app_womenhealth.js")
async def serve_app_js():
    """Serve JavaScript file"""
    js_path = "app_womenhealth.js"
    if os.path.exists(js_path):
        return FileResponse(
            js_path,
            media_type="application/javascript",
            headers={
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )
    raise HTTPException(status_code=404, detail="app_womenhealth.js not found")

@app.get("/style_womenhealth.css")
async def serve_style_css():
    """Serve CSS file"""
    css_path = "style_womenhealth.css"
    if os.path.exists(css_path):
        return FileResponse(
            css_path,
            media_type="text/css",
            headers={
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )
    raise HTTPException(status_code=404, detail="style_womenhealth.css not found")


@app.post("/api/doctor-contacts", response_model=DoctorContactResponse)
async def get_doctor_contacts(request: DoctorContactRequest):
    """
    Get doctor contact information for a specific district
    """
    print(f"\nüìû Doctor contact request for: {request.district}")

    contact_info = get_doctor_contacts_for_district(request.district)

    return DoctorContactResponse(
        district=request.district,
        contact_info=contact_info,
        status="success"
    )


@app.get("/api/districts")
async def get_districts():
    """
    Get list of available districts
    """
    return {
        "districts": DISTRICTS,
        "count": len(DISTRICTS)
    }


@app.post("/query")
async def query(data: QueryData):
    try:
        print("QueryData", data)

        # 1. ‡¶ú‡ßá‡¶≤‡¶æ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶ï ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó‡ßá‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        if data.district_selection and data.district_selection in WOMENS_HEALTH_RESOURCES:
            district_name = data.district_selection

            # ‡¶∞‡¶ø‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶°‡ßá‡¶ü‡¶æ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            resources = WOMENS_HEALTH_RESOURCES[district_name]["centers"]

            # ‡¶°‡ßá‡¶ü‡¶æ ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶Ç ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            response_text = f"‚úÖ **{district_name} ‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶∏‡ßç‡¶•‡¶æ‡¶®‡ßÄ‡¶Ø‡¶º ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ì ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó‡ßá‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø:**\n\n"

            for i, center in enumerate(resources):
                response_text += f"{i + 1}. **{center['name']}**\n"
                response_text += f"   üìû ‡¶´‡ßã‡¶®: {center['phone']}\n"
                response_text += f"   üìç ‡¶†‡¶ø‡¶ï‡¶æ‡¶®‡¶æ: {center['address']}\n"

                # ‡¶°‡ßá‡¶ü‡¶æ‡¶∞ ‡¶∂‡ßá‡¶∑‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶∞‡ßá‡¶ï ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶∏‡ßá‡¶ü‡¶ø ‡¶∂‡ßá‡¶∑ ‡¶®‡¶æ ‡¶π‡ßü
                if i < len(resources) - 1:
                    response_text += "\n"

            # RAG ‡¶≤‡¶ú‡¶ø‡¶ï ‡¶¨‡¶æ‡¶á‡¶™‡¶æ‡¶∏ ‡¶ï‡¶∞‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶§‡¶•‡ßç‡¶Ø ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡¶ø‡¶®
            return {"answer": response_text, "status": "contact_success"}

        # ‡¶Ø‡¶¶‡¶ø ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶∞‡ßã‡¶ß ‡¶®‡¶æ ‡¶π‡¶Ø‡¶º ‡¶¨‡¶æ ‡¶ú‡ßá‡¶≤‡¶æ ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶§‡¶¨‡ßá RAG ‡¶≤‡¶ú‡¶ø‡¶ï‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶®
        # ... (‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶Æ‡¶æ‡¶® RAG ‡¶≤‡¶ú‡¶ø‡¶ï ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶π‡¶¨‡ßá)

    except Exception as e:
        # üõë CRITICAL LOGGING: Print the exact error and the raw request body
        print("\n" + "=" * 50)
        print("üö® 422 VALIDATION ERROR DEBUG START üö®")
        print(f"Error Type: {type(e).__name__}")

        # Pydantic's validation error has a useful .errors() method
        if hasattr(e, 'errors'):
            print("Pydantic Validation Errors:")
            # Use json.dumps to print the errors cleanly
            import json
            print(json.dumps(e.errors(), indent=4, ensure_ascii=False))

        # Re-raise the exception to send the proper 422 status back to the client
        raise HTTPException(
            status_code=422,
            detail={"message": "Data validation failed. Check server logs for details."}
        )

# @app.post("/api/rag-query", response_model=RAGQueryResponse)
# async def rag_query(request: RAGQueryRequest):
#     """
#     Process RAG query with enhanced Bengali extraction
#     """
#     print("RAG query invoked")
#     if not rag_chain:
#         raise HTTPException(status_code=500, detail="RAG system not initialized")
#
#     try:
#         # Extract category and subcategory from query
#         category_match = re.search(r'‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó:\s*(\w+)', request.query)
#         subcategory_match = re.search(r'‡¶â‡¶™‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó:\s*([^‡•§]+)', request.query)
#
#         category = category_match.group(1) if category_match else ""
#         subcategory = subcategory_match.group(1).strip() if subcategory_match else ""
#
#         # Extract only Bengali answers from Q&A history
#         if 'Q1:' in request.query or 'A1:' in request.query:
#             # Find the answers section
#             answers_section = re.search(r'‡¶â‡¶§‡ßç‡¶§‡¶∞:\s*(.+)$', request.query, re.DOTALL)
#             if answers_section:
#                 qa_text = answers_section.group(1)
#                 bengali_answers = extract_bengali_answers(qa_text)
#             else:
#                 bengali_answers = extract_bengali_answers(request.query)
#
#             # Create focused Bengali query
#             focused_query = create_bengali_query(
#                 category,
#                 subcategory,
#                 bengali_answers,
#                 request.question_stage
#             )
#         else:
#             # Direct followup question
#             focused_query = request.query
#
#         print(f"\n{'=' * 70}")
#         print(f"üìù Processing RAG Query")
#         print(f"{'=' * 70}")
#         print(f"Stage: {request.question_stage}")
#         print(f"Category: {category}")
#         print(f"Subcategory: {subcategory}")
#         print(f"Original query length: {len(request.query)} chars")
#         print(f"Focused query: {focused_query[:200]}...")
#         print(f"Focused query length: {len(focused_query)} chars")
#
#         # Call RAG chain
#
#         response = rag_chain({"question": focused_query, "chat_history": "\n".join(request.conversation_history)})
#
#         answer = response.get("answer", "")
#         source_docs = response.get("source_documents", [])
#
#         if not answer:
#             answer = "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶è‡¶á ‡¶Æ‡ßÅ‡¶π‡ßÇ‡¶∞‡ßç‡¶§‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶õ‡¶ø ‡¶®‡¶æ‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
#
#         print(f"\n‚úÖ Response Generated:")
#         print(f"   Answer length: {len(answer)} chars")
#         print(f"   Source documents: {len(source_docs)}")
#         print(f"   Answer preview: {answer[:150]}...")
#
#         # Extract actual source file names from documents
#         source_files = set()
#         if source_docs:
#             for doc in source_docs:
#                 if hasattr(doc, 'metadata') and 'source' in doc.metadata:
#                     source_files.add(os.path.basename(doc.metadata['source']))
#
#         # Add citations with actual source files
#         citations = None
#         if request.question_stage == "after_q5":
#             citations = "\n\nüìö **‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞:** ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ (WHO), ICMR, NFHS-5"
#         elif request.question_stage == "after_q12":
#             citations = "\n\nüìö **‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞:** ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ (WHO), ICMR, NFHS-5, The Lancet, ‡¶≠‡¶æ‡¶∞‡¶§‡ßÄ‡¶Ø‡¶º ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶Æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ï"
#         else:
#             citations = "\n\nüìö **‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞:** ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ (WHO), ICMR"
#
#         if source_docs:
#             citations += f"\n\nüîç **‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶â‡ßé‡¶∏:** {len(source_docs)} ‡¶ü‡¶ø ‡¶®‡¶•‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá"
#             if source_files:
#                 citations += f"\nüìÑ **‡¶´‡¶æ‡¶á‡¶≤:** {', '.join(source_files)}"
#
#         print(f"   Source files: {source_files}")
#         print(f"{'=' * 70}\n")
#
#         sourcedocs = response.get("source_documents", [])
#         ncitations = [os.path.basename(doc.metadata["source"]) for doc in sourcedocs if
#                      hasattr(doc, "metadata") and "source" in doc.metadata]
#         print("Final citations", ncitations)
#
#         return RAGQueryResponse(
#             answer=answer,
#             citations=citations,
#             status="success"
#         )
#
#     except Exception as e:
#         print(f"\n‚ùå Error processing query:")
#         print(f"   {type(e).__name__}: {str(e)}")
#         import traceback
#         traceback.print_exc()
#
#         raise HTTPException(status_code=500, detail=f"Error: {str(e)}")





def fetch_internet_snippet(query: str) -> str:
    url = f"https://duckduckgo.com/html/?q={query}"
    try:
        resp = requests.get(url, timeout=6)
        # crude but effective snippet extraction
        soup = BeautifulSoup(resp.text, 'html.parser')
        result = soup.find("a", {"class": "result__snippet"})
        return result.get_text(strip=True) if result else "No internet info."
    except Exception as e:
        print("DuckDuckGo error:", str(e))
        return "No internet info available."


@app.post("/api/rag-query", response_model=RAGQueryResponse)
async def rag_query(request: RAGQueryRequest):
    print("RAG query invoked")
    if not rag_chain:
        raise HTTPException(status_code=500, detail="RAG system not initialized")
    try:
        # Compose context
        chat_history = "\n".join(request.conversation_history)

        # Custom handling for summary (Q1‚ÄìQ5) vs detailed answer (Q6‚ÄìQ12)
        if request.question_stage == 'after_q5':
            prompt = ("Summarize the main health concerns/issues the user described in Q1‚ÄìQ5 in 2 lines. Begin the answer by referring to the user context only"
                      "Do provide 2-3 lines advice based on the context, do not repeat this summary later.")
        elif request.question_stage == 'after_q12':
            prompt = ("Given ALL information from Q1‚ÄìQ12, provide a detailed, actionable health answer. "
                      "Reference any symptoms or history, but do NOT repeat the summary from Q1‚ÄìQ5. "
                      "If local corpus retrieval is insufficient, supplement with info from public internet sources.")
        else:
            prompt = "Respond helpfully using the provided context only, begin the answer by referring to the user context only."

        # Focused query: direct user query + custom prompt
        focused_query = f"{request.query}\n\n{prompt}"

        # Run RAG chain with context
        response = rag_chain({
            "question": focused_query,
            "chat_history": chat_history
        })
        answer = response.get("answer", "")
        sourcedocs = response.get("source_documents", [])

        # --- Internet Fallback Logic ---
        answer_is_short = len(answer.strip()) < 100 or "insufficient" in answer.lower()
        internet_snippet = ""
        if answer_is_short:
            # Replace with your function for external web info, e.g. using Bing or Google API
            internet_snippet = fetch_internet_snippet(request.query)
            if internet_snippet:
                answer += f"\n\n[Web info] {internet_snippet}"

        print("Internet snippet", internet_snippet)
        citations = "jnm.txt"
        # --- Citations ---
        # Existing code builds citations as a list:
        # citations = [os.path.basename(doc.metadata["source"]) for doc in sourcedocs if
        #              hasattr(doc, "metadata") and "source" in doc.metadata]
        # if internet_snippet:
        #     citations.append("internet")
        # citations_str = ", ".join(citations)
        #
        # print(f"Final answer: {answer[:150]}... citations: {citations}")

        return RAGQueryResponse(answer=answer, citations=citations, status="success")
    except Exception as e:
        print("Error processing RAG query", str(e))
        import traceback;
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")



@app.get("/health")
async def health_check():
    """Health check with corpus info"""
    corpus_status = []
    for file in CORPUS_FILES:
        exists = os.path.exists(file)
        size = os.path.getsize(file) if exists else 0
        corpus_status.append({
            "file": file,
            "exists": exists,
            "size_bytes": size
        })

    return {
        "status": "healthy",
        "rag_initialized": rag_chain is not None,
        "model": MODEL_NAME,
        "corpus_files": corpus_status,
        "districts_available": DISTRICTS
    }


# Streamlit compatibility endpoints
@app.get("/_stcore/health")
async def streamlit_health_check():
    return {"status": "ok"}


@app.get("/_stcore/host-config")
async def streamlit_host_config():
    return {
        "allowedOrigins": ["*"],
        "useExternalAuthToken": False,
        "enableXsrfProtection": False
    }


@app.websocket("/_stcore/stream")
async def streamlit_stream(websocket: WebSocket):
    await websocket.accept()
    print("üîå WebSocket connected")
    try:
        while True:
            try:
                await asyncio.wait_for(websocket.receive_text(), timeout=30.0)
                await websocket.send_json({"type": "ping"})
            except asyncio.TimeoutError:
                await websocket.send_json({"type": "heartbeat"})
    except WebSocketDisconnect:
        print("üîå WebSocket disconnected")


if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("üöÄ Starting Narishakti Backend...")
    print("=" * 60)
    print(f"üì° Server: http://localhost:8502")
    print(f"ü§ñ Model: {MODEL_NAME}")
    print(f"üìö Corpus: {CORPUS_FILES}")
    print(f"üè• Districts: {len(DISTRICTS)}")
    print("=" * 60 + "\n")

    uvicorn.run(app, host="0.0.0.0", port=8502, log_level="info")